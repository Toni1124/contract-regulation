import psycopg2
from multiprocessing import Pool, cpu_count
from config import DB_CONFIG, BATCH_SIZE, MAX_WORKERS
from abi_manager import ABIManager
from logger import logger
from tqdm import tqdm
import time
import json
from rule_processor import RuleProcessor

class TransactionProcessor:
    def __init__(self):
        self.max_processes = cpu_count()*2  # ä½¿ç”¨CPUæ ¸å¿ƒæ•°é‡ä½œä¸ºè¿›ç¨‹æ•°
        
    def process_batch_worker(self, batch_params):
        """
        å·¥ä½œè¿›ç¨‹å¤„ç†å•ä¸ªæ‰¹æ¬¡
        """
        start_block, end_block, contract_addresses = batch_params
        conn = None
        cursor = None
        try:
            print(f"\nðŸ“¦ è¿›ç¨‹å¼€å§‹å¤„ç†æ‰¹æ¬¡: {start_block} -> {end_block}")
            conn = psycopg2.connect(**DB_CONFIG)
            cursor = conn.cursor()
            
            # åœ¨æ¯ä¸ªå·¥ä½œè¿›ç¨‹ä¸­åˆ›å»ºæ–°çš„ABIManagerå®žä¾‹
            abi_manager = ABIManager()
            
            # åˆå§‹åŒ–è§„åˆ™å¤„ç†å™¨
            rule_processor = RuleProcessor(DB_CONFIG)
            
            # åŠ è½½æ‰€æœ‰è§„åˆ™ - ä¸ä½¿ç”¨withè¯­å¥
            contract_rules = rule_processor.load_rules(cursor)
            
            # èŽ·å–åŽŸå§‹äº¤æ˜“æ•°æ®
            query = """
            SELECT * FROM "default".eth_transaction
            WHERE block_number BETWEEN %s AND %s
            AND to_address = ANY(%s)
            ORDER BY block_number, transaction_index
            """
            
            cursor.execute(query, (start_block, end_block, contract_addresses))
            transactions = cursor.fetchall()
            
            if not transactions:
                print(f"â„¹ï¸ åŒºå— {start_block}-{end_block} æ²¡æœ‰æ‰¾åˆ°äº¤æ˜“")
                return 0, 0

            print(f"ðŸ” åŒºå— {start_block}-{end_block} æ‰¾åˆ° {len(transactions)} ç¬”äº¤æ˜“")
            
            # èŽ·å–åˆ—å
            cursor.execute("""
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_schema = 'default' 
                AND table_name = 'eth_transaction' 
                ORDER BY ordinal_position
            """)
            columns = [col[0] for col in cursor.fetchall()]
            
            success_count = 0
            error_count = 0
            
            # å¤„ç†æ¯ä¸ªäº¤æ˜“
            for tx in transactions:
                try:
                    tx_dict = dict(zip(columns, tx))
                    
                    to_address = tx_dict.get('to_address')
                    if not to_address:
                        continue
                    
                    input_data = tx_dict.get('input')
                    if not input_data:
                        input_data = '0x'
                    
                    # ä½¿ç”¨å±€éƒ¨çš„abi_manager
                    func_signature, func_name, decoded_params = abi_manager.decode_input(
                        to_address.strip(), input_data
                    )
                    
                    # å‡†å¤‡æ’å…¥æ•°æ®
                    insert_data = [
                        tx_dict.get('block_number'),
                        tx_dict.get('block_timestamp'),
                        tx_dict.get('transaction_index'),
                        tx_dict.get('value'),
                        tx_dict.get('gas'),
                        tx_dict.get('gas_price'),
                        tx_dict.get('nonce'),
                        tx_dict.get('from_address'),
                        tx_dict.get('to_address'),
                        tx_dict.get('receipt_contract_address'),
                        tx_dict.get('receipt_root'),
                        tx_dict.get('block_hash'),
                        tx_dict.get('input'),
                        tx_dict.get('blob_versioned_hashes'),
                        tx_dict.get('hash'),
                        func_signature,
                        func_name,
                        json.dumps(decoded_params) if decoded_params else None
                    ]
                    
                    # ä½¿ç”¨å…·ä½“çš„åˆ—åè¿›è¡Œæ’å…¥
                    insert_query = """
                    INSERT INTO eth_transaction_details (
                        block_number, block_timestamp, transaction_index, value, gas, 
                        gas_price, nonce, from_address, to_address, receipt_contract_address,
                        receipt_root, block_hash, input, blob_versioned_hashes, hash,
                        function_signature, function_name, decoded_parameters
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (block_number, transaction_index) DO UPDATE SET
                        function_signature = EXCLUDED.function_signature,
                        function_name = EXCLUDED.function_name,
                        decoded_parameters = EXCLUDED.decoded_parameters;
                    """
                    
                    cursor.execute(insert_query, insert_data)
                    
                    # è§„åˆ™æ£€æŸ¥ä½¿ç”¨åŒä¸€ä¸ªcursor
                    if func_name and decoded_params:
                        tx_dict = {
                            'block_number': insert_data[0],
                            'transaction_index': insert_data[2],
                            'to_address': insert_data[8],
                            'function_name': func_name,
                            'decoded_parameters': json.dumps(decoded_params)
                        }
                        
                        check_result, check_message = rule_processor.check_transaction(
                            tx_dict, 
                            cursor  # ä½¿ç”¨åŒä¸€ä¸ªcursor
                        )
                        
                        rule_processor.update_transaction_rules_check(
                            cursor,  # ä½¿ç”¨åŒä¸€ä¸ªcursor
                            tx_dict,
                            check_result,
                            check_message
                        )
                    else:
                        tx_dict = {
                            'block_number': insert_data[0],
                            'transaction_index': insert_data[2]
                        }
                        rule_processor.update_transaction_rules_check(
                            cursor,  # ä½¿ç”¨åŒä¸€ä¸ªcursor
                            tx_dict,
                            True,
                            "é€šè¿‡ç›‘ç®¡ï¼ˆæ— éœ€è§£ç çš„äº¤æ˜“ï¼‰"
                        )
                    
                    conn.commit()
                    success_count += 1
                    
                except Exception as e:
                    conn.rollback()
                    error_count += 1
                    print(f"âŒ Error processing transaction at block={tx_dict.get('block_number', 'unknown')}: {str(e)}")
                    continue
            
            return success_count, error_count

        except Exception as e:
            print(f"âŒ Batch error {start_block}-{end_block}: {str(e)}")
            return 0, 0
        finally:
            if cursor:
                cursor.close()
            if conn:
                conn.close()

    def process_range(self, begin_block, end_block, contract_addresses):
        """
        ä½¿ç”¨å¤šè¿›ç¨‹å¤„ç†åŒºå—èŒƒå›´
        """
        print(f"\nðŸš€ å¼€å§‹å¤„ç†åŒºå—èŒƒå›´: {begin_block} -> {end_block}")
        
        # è®¡ç®—æ‰¹æ¬¡
        batches = []
        current_block = begin_block
        while current_block < end_block:
            batch_end = min(current_block + BATCH_SIZE, end_block)
            batches.append((current_block, batch_end, contract_addresses))
            current_block = batch_end + 1
        
        total_batches = len(batches)
        print(f"ðŸ“‘ æ€»æ‰¹æ¬¡æ•°: {total_batches}")
        print(f"ðŸ’» ä½¿ç”¨è¿›ç¨‹æ•°: {self.max_processes}")
        
        start_time = time.time()
        
        # ä½¿ç”¨è¿›ç¨‹æ± å¤„ç†æ‰¹æ¬¡
        with Pool(processes=self.max_processes) as pool:
            results = pool.map(self.process_batch_worker, batches)
        
        # ç»Ÿè®¡ç»“æžœ
        total_success = sum(success for success, _ in results)
        total_errors = sum(errors for _, errors in results)
        
        total_time = time.time() - start_time
        print(f"\nâœ¨ å¤„ç†å®Œæˆ:")
        print(f"   - æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   - æˆåŠŸ: {total_success}")
        print(f"   - å¤±è´¥: {total_errors}")
        print(f"   - å¹³å‡æ¯æ‰¹æ¬¡è€—æ—¶: {total_time/total_batches:.2f}ç§’")

    def recheck_existing_transactions(self, contract_addresses=None):
        """
        é‡æ–°æ£€æŸ¥å·²å­˜åœ¨çš„äº¤æ˜“
        :param contract_addresses: å¯é€‰ï¼ŒæŒ‡å®šè¦é‡æ–°æ£€æŸ¥çš„åˆçº¦åœ°å€åˆ—è¡¨
        """
        try:
            print("\nðŸš€ å¼€å§‹é‡æ–°æ£€æŸ¥å·²å­˜åœ¨çš„äº¤æ˜“...")
            conn = psycopg2.connect(**DB_CONFIG)
            
            # åˆå§‹åŒ–è§„åˆ™å¤„ç†å™¨
            rule_processor = RuleProcessor(DB_CONFIG)
            
            # æ‰§è¡Œé‡æ–°æ£€æŸ¥
            rule_processor.recheck_transactions(conn, contract_addresses)
            
            print("âœ¨ é‡æ–°æ£€æŸ¥å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ é‡æ–°æ£€æŸ¥è¿‡ç¨‹å‡ºé”™: {str(e)}")
        finally:
            if conn:
                conn.close()

    def warm_up_pool(self):
        """é¢„çƒ­è¿›ç¨‹æ± ï¼Œé¿å…å†·å¯åŠ¨å¼€é”€"""
        with Pool(processes=self.max_processes) as pool:
            pool.map(lambda x: None, range(self.max_processes))
